{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7bwrHTCfjvKj"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-10 14:17:06.824981: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-10 14:17:08.048706: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import os\n",
        "import random\n",
        "import base64\n",
        "import logging\n",
        "import pathlib\n",
        "import typing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import keras\n",
        "from listy import parseData\n",
        "from listy import XDfunc\n",
        "from listy import generate_and_save_all_output_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#parse data\n",
        "XDfunc([\"/home/lojek/WTUM_2024_2/classification/data/csv/data_rand\",\n",
        "        \"/home/lojek/WTUM_2024_2/classification/data/csv/data_rand1\",\n",
        "        \"/home/lojek/WTUM_2024_2/classification/data/csv/data_rand2\",\n",
        "        \"/home/lojek/WTUM_2024_2/classification/data/csv/data_rand3\",\n",
        "        \"/home/lojek/WTUM_2024_2/classification/data/csv/data_rand4\",\n",
        "        \"/home/lojek/WTUM_2024_2/classification/data/csv/data_rand5\",\n",
        "        \"/home/lojek/WTUM_2024_2/classification/data/csv/data_rand6\",\n",
        "        \"/home/lojek/WTUM_2024_2/classification/data/csv/data_rand7\",\n",
        "        \"/home/lojek/WTUM_2024_2/classification/data/csv/data_rand8\",\n",
        "        \"/home/lojek/WTUM_2024_2/classification/data/csv/data_rand9\",\n",
        "        \"/home/lojek/WTUM_2024_2/classification/data/csv/data_rand10\",\n",
        "        \"/home/lojek/WTUM_2024_2/classification/data/csv/data_rand11\",\n",
        "        \"/home/lojek/WTUM_2024_2/classification/data/csv/data_rand12\",\n",
        "        \"/home/lojek/WTUM_2024_2/classification/data/csv/data_rand13\",\n",
        "        \"/home/lojek/WTUM_2024_2/classification/data/csv/data_rand14\",\n",
        "        \"/home/lojek/WTUM_2024_2/classification/data/csv/data_rand15\",\n",
        "        \"/home/lojek/WTUM_2024_2/classification/data/csv/data_rand16\",\n",
        "        \"/home/lojek/WTUM_2024_2/classification/data/csv/data_rand17\",\n",
        "        \"/home/lojek/WTUM_2024_2/classification/data/csv/data_to8\",\n",
        "        \n",
        "       ],\"/home/lojek/WTUM_2024_2/classification/data/npy/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#loaddata\n",
        "array_data_filename = pathlib.Path(\"/home/lojek/WTUM_2024_2/classification/data/npy/arrayData.npy\")\n",
        "number_data_filename = pathlib.Path(\"/home/lojek/WTUM_2024_2/classification/data/npy/numberData.npy\")\n",
        "target_data_filename = pathlib.Path(\"/home/lojek/WTUM_2024_2/classification/data/npy/targetData.npy\")\n",
        "\n",
        "if array_data_filename.is_file() and number_data_filename.is_file() and target_data_filename.is_file():\n",
        "    logging.info(\"Loading data from .npy files\")\n",
        "    array_data_full = np.load(array_data_filename, mmap_mode = \"r\")\n",
        "    number_data_full = np.load(number_data_filename, mmap_mode = \"r\")\n",
        "    target_data_full = np.load(target_data_filename, mmap_mode = \"r\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get full data sample\n",
        "array_data =array_data_full\n",
        "number_data = number_data_full\n",
        "target_data = target_data_full\n",
        "generate_and_save_all_output_matrix(array_data,\"/home/lojek/WTUM_2024_2/classification/data/npy/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get smaller data sample\n",
        "indices = random.sample(range(len(target_data_full)), 100000)\n",
        "\n",
        "array_data = []\n",
        "number_data = []\n",
        "target_data = []\n",
        "\n",
        "for index in indices:\n",
        "    array_data.append(array_data_full[index])\n",
        "    number_data.append(number_data_full[index])\n",
        "    target_data.append(target_data_full[index])\n",
        "\n",
        "array_data = np.array(array_data)\n",
        "number_data = np.array(number_data)\n",
        "target_data = np.array(target_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-08 10:35:08.507556: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-05-08 10:35:08.536445: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-05-08 10:35:08.536497: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-05-08 10:35:08.540444: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-05-08 10:35:08.540545: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-05-08 10:35:08.540581: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-05-08 10:35:08.656637: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-05-08 10:35:08.656692: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-05-08 10:35:08.656700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
            "2024-05-08 10:35:08.656732: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-05-08 10:35:08.656752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "# load model\n",
        "import tensorflow as tf\n",
        "MODEL_PATH = \"/home/lojek/WTUM_2024_2/classification/models/gruba-berta/2024-05-08_10-34-20.keras\"\n",
        "model = tf.keras.models.load_model(\n",
        "    MODEL_PATH\n",
        ")\n",
        "MODEL_NAME = \"gruba-berta\"\n",
        "MODEL_PATH = pathlib.Path(\"models\") / MODEL_NAME\n",
        "LOSS = \"mean_squared_error\"\n",
        "METRICS = [\"mae\"]\n",
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup variables\n",
        "MODEL_NAME = \"gruba-berta\"\n",
        "MODEL_PATH = pathlib.Path(\"models\") / MODEL_NAME\n",
        "LOSS = \"mean_squared_error\"\n",
        "METRICS = [\"mae\"]\n",
        "BATCH_SIZE = 160"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#testy\n",
        "#model.predict([np.array([0]),np.array(array_data[None,0])])\n",
        "board=array_data[0]\n",
        "print(model.predict([np.array([0]),np.array(board)]))\n",
        "#print(number_data_full[0])\n",
        "#np.array(array_data_full[0]).shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create model\n",
        "\n",
        "# Define the input layers\n",
        "number_input = keras.layers.Input(shape = (1,), name = \"number_input\") # type: ignore\n",
        "array_input = keras.layers.Input(shape = (6, 7, 2), name = \"array_input\")\n",
        "\n",
        "# Flatten the array input\n",
        "flattened_array = keras.layers.Flatten()(array_input)\n",
        "\n",
        "# Concatenate the flattened array input with the number input\n",
        "concatenated_input = keras.layers.Concatenate()([number_input, flattened_array])\n",
        "\n",
        "# Dense layers for processing concatenated inputs\n",
        "dense1 = keras.layers.Dense(1024, activation = \"relu\")(concatenated_input)\n",
        "dense2 = keras.layers.Dense(1024, activation = \"relu\")(dense1)\n",
        "dense3 = keras.layers.Dense(1024, activation = \"relu\")(dense2)\n",
        "\n",
        "# Convolutional layers for processing the array input\n",
        "conv1 = keras.layers.Conv2D(1024, kernel_size = (3, 3), activation = \"relu\", padding = \"same\")(array_input)\n",
        "pool1 = keras.layers.MaxPooling2D(pool_size = (2, 2))(conv1)\n",
        "conv2 = keras.layers.Conv2D(1024, kernel_size = (3, 3), activation = \"relu\", padding = \"same\")(pool1)\n",
        "pool2 = keras.layers.MaxPooling2D(pool_size = (2, 2))(conv2)\n",
        "flatten = keras.layers.Flatten()(pool2)\n",
        "\n",
        "dense4 = keras.layers.Dense(1024, activation = \"relu\")(flatten)\n",
        "dense5 = keras.layers.Dense(1024, activation = \"relu\")(dense4)\n",
        "dense6 = keras.layers.Dense(1024, activation = \"relu\")(dense5)\n",
        "\n",
        "# Concatenate the output of the dense and convolutional layers\n",
        "concatenated_output = keras.layers.Concatenate()([dense3, dense6])\n",
        "\n",
        "# Additional Dense layers\n",
        "dense7 = keras.layers.Dense(1024, activation = \"relu\")(concatenated_output)\n",
        "dense8 = keras.layers.Dense(1024, activation = \"relu\")(dense7)\n",
        "dense9 = keras.layers.Dense(1024, activation = \"relu\")(dense8)\n",
        "dense10 = keras.layers.Dense(1024, activation = \"relu\")(dense9)\n",
        "dense11 = keras.layers.Dense(1024, activation = \"relu\")(dense10)\n",
        "\n",
        "# Output layer\n",
        "output = keras.layers.Dense(7, activation = \"linear\", name = \"output\")(dense11)\n",
        "\n",
        "# Create the model\n",
        "model = keras.models.Model(inputs = [number_input, array_input], outputs = output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer = \"adam\", loss = LOSS, metrics = METRICS)\n",
        "\n",
        "# Print model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d2x5jY0ejvKp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1715157314.757277   25024 service.cc:145] XLA service 0x7fc9a8016b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1715157314.757325   25024 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
            "2024-05-08 10:35:14.803592: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2024-05-08 10:35:15.086433: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1715157316.568161   25116 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_781', 8 bytes spill stores, 8 bytes spill loads\n",
            "\n",
            "I0000 00:00:1715157317.021460   25115 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_781', 856 bytes spill stores, 856 bytes spill loads\n",
            "\n",
            "I0000 00:00:1715157317.209001   25109 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_612', 192 bytes spill stores, 192 bytes spill loads\n",
            "\n",
            "I0000 00:00:1715157317.739715   25110 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1060', 124 bytes spill stores, 276 bytes spill loads\n",
            "\n",
            "I0000 00:00:1715157318.449992   25106 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_781', 380 bytes spill stores, 380 bytes spill loads\n",
            "\n",
            "I0000 00:00:1715157318.497511   25107 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1060', 8 bytes spill stores, 8 bytes spill loads\n",
            "\n",
            "I0000 00:00:1715157319.289520   25112 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_612', 644 bytes spill stores, 816 bytes spill loads\n",
            "\n",
            "I0000 00:00:1715157319.422494   25118 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1060', 164 bytes spill stores, 164 bytes spill loads\n",
            "\n",
            "I0000 00:00:1715157319.886925   25119 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1060', 8 bytes spill stores, 8 bytes spill loads\n",
            "\n",
            "I0000 00:00:1715157320.066947   25106 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1060', 44 bytes spill stores, 44 bytes spill loads\n",
            "\n",
            "2024-05-08 10:35:22.128270: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.33GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m    7/55548\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:54\u001b[0m 23ms/step - loss: 15.0394 - mae: 2.3144 "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1715157324.683701   25024 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_7', 16 bytes spill stores, 16 bytes spill loads\n",
            "\n",
            "I0000 00:00:1715157324.687397   25024 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55547/55548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 26.8743 - mae: 2.0034"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1715158544.138767   33720 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1060', 20 bytes spill stores, 20 bytes spill loads\n",
            "\n",
            "I0000 00:00:1715158544.237989   33718 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1060', 444 bytes spill stores, 444 bytes spill loads\n",
            "\n",
            "I0000 00:00:1715158544.417591   33731 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_1060', 436 bytes spill stores, 436 bytes spill loads\n",
            "\n",
            "I0000 00:00:1715158545.103193   33721 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_781', 944 bytes spill stores, 616 bytes spill loads\n",
            "\n",
            "I0000 00:00:1715158546.162115   33718 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_781', 460 bytes spill stores, 348 bytes spill loads\n",
            "\n",
            "I0000 00:00:1715158546.314430   33719 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_612', 260 bytes spill stores, 260 bytes spill loads\n",
            "\n",
            "2024-05-08 10:55:47.710359: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.74GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m55548/55548\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 26.8744 - mae: 2.0034"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1715158549.139843   25018 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_7', 16 bytes spill stores, 16 bytes spill loads\n",
            "\n",
            "I0000 00:00:1715158635.719190   34532 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_153', 460 bytes spill stores, 348 bytes spill loads\n",
            "\n",
            "I0000 00:00:1715158635.902312   34536 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_153', 944 bytes spill stores, 616 bytes spill loads\n",
            "\n",
            "I0000 00:00:1715158636.122528   34533 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_82', 260 bytes spill stores, 260 bytes spill loads\n",
            "\n",
            "I0000 00:00:1715158636.169659   34540 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_82', 4 bytes spill stores, 4 bytes spill loads\n",
            "\n",
            "I0000 00:00:1715158636.193546   34538 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_82', 380 bytes spill stores, 232 bytes spill loads\n",
            "\n",
            "2024-05-08 10:57:16.434116: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 19.90MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2024-05-08 10:57:16.437316: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at xla_ops.cc:580 : UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
            "%cudnn-conv-bias-activation.7 = (f32[111,1024,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[111,1024,3,3]{3,2,1,0} %reduce-window.4, f32[1024,1024,3,3]{3,2,1,0} %transpose.10, f32[1024]{0} %arg6.7), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv2d_1_2/convolution\" source_file=\"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n",
            "\n",
            "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 20869120 bytes.\n",
            "\n",
            "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
            "2024-05-08 10:57:16.437377: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n",
            "%cudnn-conv-bias-activation.7 = (f32[111,1024,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[111,1024,3,3]{3,2,1,0} %reduce-window.4, f32[1024,1024,3,3]{3,2,1,0} %transpose.10, f32[1024]{0} %arg6.7), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv2d_1_2/convolution\" source_file=\"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n",
            "\n",
            "Original error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 20869120 bytes.\n",
            "\n",
            "To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n",
            "\t [[{{node StatefulPartitionedCall}}]]\n"
          ]
        },
        {
          "ename": "UnknownError",
          "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_24870/2230435322.py\", line 2, in <module>\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 339, in fit\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 425, in evaluate\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 161, in one_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bias-activation.7 = (f32[111,1024,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[111,1024,3,3]{3,2,1,0} %reduce-window.4, f32[1024,1024,3,3]{3,2,1,0} %transpose.10, f32[1024]{0} %arg6.7), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv2d_1_2/convolution\" source_file=\"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 20869120 bytes.\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_iterator_337801]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumber_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39msave(MODEL_PATH \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mtoday()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/WTUM_2024_2/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/WTUM_2024_2/venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_24870/2230435322.py\", line 2, in <module>\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 339, in fit\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 425, in evaluate\n\n  File \"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 161, in one_step_on_iterator\n\nFailed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bias-activation.7 = (f32[111,1024,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[111,1024,3,3]{3,2,1,0} %reduce-window.4, f32[1024,1024,3,3]{3,2,1,0} %transpose.10, f32[1024]{0} %arg6.7), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"functional_1_1/conv2d_1_2/convolution\" source_file=\"/home/lojek/WTUM_2024_2/venv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\" source_line=1177}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}}\n\nOriginal error: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 20869120 bytes.\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_iterator_337801]"
          ]
        }
      ],
      "source": [
        "# Fit model\n",
        "model.fit([number_data, array_data], target_data, epochs = 1, batch_size = BATCH_SIZE, validation_split = 0.2)\n",
        "# Save model\n",
        "model.save(MODEL_PATH / f\"{dt.datetime.today().strftime('%Y-%m-%d_%H-%M-%S')}.keras\")\n",
        "# Fit model\n",
        "model.fit([number_data, array_data], target_data, epochs = 1, batch_size = BATCH_SIZE, validation_split = 0.2)\n",
        "# Save model\n",
        "model.save(MODEL_PATH / f\"{dt.datetime.today().strftime('%Y-%m-%d_%H-%M-%S')}.keras\")\n",
        "# Fit model\n",
        "model.fit([number_data, array_data], target_data, epochs = 1, batch_size = BATCH_SIZE, validation_split = 0.2)\n",
        "# Save model\n",
        "model.save(MODEL_PATH / f\"{dt.datetime.today().strftime('%Y-%m-%d_%H-%M-%S')}.keras\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAkPO5vDjvKq"
      },
      "outputs": [],
      "source": [
        "# Test model\n",
        "test_loss, test_mertics = model.evaluate([number_data, array_data], target_data, batch_size = BATCH_SIZE)\n",
        "print(f\"Test loss: {test_loss}, Test metrics: {test_mertics}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "y0cu7U9VjvKr"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "model.save(MODEL_PATH / f\"{dt.datetime.today().strftime('%Y-%m-%d_%H-%M-%S')}.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train model\n",
        "while True:\n",
        "    model_name = sorted([f for f in os.listdir(MODEL_PATH) if os.path.isfile(os.path.join(MODEL_PATH, f)) and f.endswith(\".keras\")])[-1]\n",
        "    model: typing.Any = keras.models.load_model(MODEL_PATH / model_name)\n",
        "    model.compile(optimizer = \"adam\", loss = LOSS, metrics = METRICS)\n",
        "    model.fit([number_data, array_data], target_data, epochs = 1, batch_size = BATCH_SIZE, validation_split = 0.2)\n",
        "    model.save(MODEL_PATH / f\"{dt.datetime.today().strftime('%Y-%m-%d_%H-%M-%S')}.keras\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
